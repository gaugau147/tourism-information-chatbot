"{\"class_name\": \"Tokenizer\", \"config\": {\"num_words\": null, \"filters\": \"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\", \"lower\": true, \"split\": \" \", \"char_level\": false, \"oov_token\": null, \"document_count\": 52, \"word_counts\": \"{\\\"greeting\\\": 13, \\\"goodbye\\\": 10, \\\"age\\\": 11, \\\"name\\\": 10, \\\"destination\\\": 8}\", \"word_docs\": \"{\\\"greeting\\\": 13, \\\"goodbye\\\": 10, \\\"age\\\": 11, \\\"name\\\": 10, \\\"destination\\\": 8}\", \"index_docs\": \"{\\\"1\\\": 13, \\\"3\\\": 10, \\\"2\\\": 11, \\\"4\\\": 10, \\\"5\\\": 8}\", \"index_word\": \"{\\\"1\\\": \\\"greeting\\\", \\\"2\\\": \\\"age\\\", \\\"3\\\": \\\"goodbye\\\", \\\"4\\\": \\\"name\\\", \\\"5\\\": \\\"destination\\\"}\", \"word_index\": \"{\\\"greeting\\\": 1, \\\"age\\\": 2, \\\"goodbye\\\": 3, \\\"name\\\": 4, \\\"destination\\\": 5}\"}}"